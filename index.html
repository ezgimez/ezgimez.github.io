<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>Ezgi's Garden</title> <header> <div class=blog-name ><a href="/">Ezgi Özyılkan</a></div> <nav> <ul> <li><a href="/teaching">Teaching</a> <li><a href="/publications">Publications</a> <li><a href="/assets/Ozyilkan_CV_Dec2023.pdf">CV</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h2 id=about_me ><a href="#about_me" class=header-anchor >About me</a></h2> <div class=row ><div class=container ><img class=left  id=profpic src="assets/profile_ezgi.jpg" > <p>Hi, I am Ezgi &#40;she/they&#41;. I am a third year <strong>PhD candidate in Electrical Engineering</strong> at <em>New York University</em> under the advisory of Professor Elza Erkip, <a href="https://wp.nyu.edu/elza_erkip/">CommIT Group at NYU</a>. I received my &#40;integrated&#41; MEng degree in Electrical Engineering from <em>Imperial College London</em> in 2021.</p> <p>My current interests are in &#40;unconventional&#41; <strong>learned compression models</strong>, <em>quantization</em> and <em>representation learning</em>. My background is in <em>&#40;information-theoretic&#41; deep learning</em> and <em>statistical signal processing</em>. Outside of academia, I hike as well as try to expand my food and coffee palate.</p> <p>I am always happy to chat about topics at the intersection of information theory and deep learning – feel free to drop me an email at <em>ezgi&#40;dot&#41;ozyilkan&#40;at&#41;nyu&#40;dot&#41;edu</em>&#33;</p> <p>Useful links: <a href="https://scholar.google.com/citations?hl&#61;en&amp;user&#61;MVZFqdQAAAAJ">Google Scholar</a> | <a href="https://www.linkedin.com/in/ezgi-&#37;C3&#37;B6zy&#37;C4&#37;B1lkan-21b2ab191/">LinkedIn</a> | <a href="https://arxiv.org/a/ozyilkan_e_1.html">arXiv</a> | <a href="https://github.com/ezgimez">GitHub</a></p></div></div> <h2 id=updates ><a href="#updates" class=header-anchor >Updates</a></h2> <ul> <li><p>February 2024: Our recent survey titled <em>&quot;Distributed Compression in the Era of Machine Learning: A Review of Recent Advances&quot;</em> will appear <a href="https://ee-ciss.princeton.edu/">at the Conference on Information Sciences and Systems &#40;CISS&#39;24&#41;</a> as an invited paper&#33; Preprint available <a href="https://arxiv.org/abs/2402.07997">here</a>.</p> </ul> <ul> <li><p>January 2024: The full program for our &#39;Learn to Compress&#39; workshop @ <a href="https://2024.ieee-isit.org/workshops">ISIT&#39;24</a> &#40;including keynote speakers and call for papers&#41; is <a href="https://learn-to-compress-workshop-isit.github.io/">out</a>.</p> </ul> <ul> <li><p>December 2023: <em>&quot;Distributed Deep Joint Source-Channel Coding with Decoder-Only Side Information&quot;</em> was accepted to the inaugural <a href="https://icmlcn2024.ieee-icmlcn.org/">2024 IEEE International Conference on Machine Learning for Communication and Networking &#40;ICMLCN&#41;</a>&#33; Preprint is available <a href="https://arxiv.org/abs/2310.04311">here</a>.</p> <li><p>November 2023: Our proposal <a href="https://2024.ieee-isit.org/workshops">&quot;Learn to Compress&quot;</a> has been accepted as a workshop at <a href="https://2024.ieee-isit.org/">ISIT 2024</a>. The proposal was put forward by <a href="https://www.ece.cornell.edu/faculty-directory/aaron-b-wagner">Aaron Wagner &#40;Cornell University&#41;</a>, <a href="https://wp.nyu.edu/elza_erkip/">Elza Erkip &#40;NYU&#41;</a> and myself. We will release more details about this workshop in December – but meanwhile, feel free to check out our <a href="https://learn-to-compress-workshop-isit.github.io/">workshop website</a>&#33; </p> <li><p>October 2023: The draft version of the journal version of our previous ISIT 2023 paper is available in <a href="https://arxiv.org/abs/2310.16961">arXiv</a>&#33; We demonstrate that the neural distributed compressor mimics the theoretical optimum for more exemplary sources :&#41; </p> <li><p>July 2023: I presented our work titled <a href="https://openreview.net/forum?id&#61;3Dq4FZJSga"><em>&quot;Neural Distributed Compressor Does Binning&quot;</em></a> at Neural Compression Workshop @ ICML&#39;23. Here are the <a href="/assets/Ozyilkan_ICML2023-workshop_final.pdf">slides</a>.</p> </ul> <ul> <li><p>July 2023: I was selected as the <em>best reviewer</em> for the <a href="https://neuralcompression.github.io/workshop23">Neural Compression Workshop @ ICML&#39;23</a>. </p> <li><p>July 2023: Our recent ISIT&#39;23 work was accepted as an <em>oral presentation</em> to <a href="https://neuralcompression.github.io/workshop23">Neural Compression Workshop @ ICML&#39;23</a>. </p> <li><p>June 2023: I presented our work titled <em>&quot;Learned Wyner–Ziv Compressors Recover Binning&quot;</em> at <a href="https://isit2023.org/">International Symposium on Information Theory &#40;ISIT&#41; 2023</a>. Here are the <a href="/assets/Ozyilkan_ISIT2023_final.pdf">slides</a>&#33;</p> <li><p>June 2023: I presented a poster about our upcoming <a href="https://arxiv.org/abs/2305.04380">ISIT&#39;23 paper</a> at <a href="https://nasit.seas.upenn.edu/home">North American School of Information Theory &#40;NASIT&#41; 2023</a>.</p> </ul> <ul> <li><p>May 2023: I presented a <a href="/assets/Ozyilkan_Simons-Institute_Poster_May2023.pdf">poster</a> titled <em>Neural Distributed Compressor Does Binning</em> at UC Berkeley Simons Institute&#39;s workshop on <a href="https://simons.berkeley.edu/talks/2023-05-24"><em>Information-Theoretic Methods for Trustworthy Machine Learning</em></a>.</p> <li><p>April 2023: <em>&quot;Learned Wyner–Ziv Compressors Recover Binning&quot;</em> was accepted to <a href="https://isit2023.org/">International Symposium on Information Theory &#40;ISIT&#41; 2023</a>. Preprint is available <a href="https://arxiv.org/abs/2305.04380">here</a>&#33;</p> <li><p>December 2022: <a href="https://arxiv.org/abs/2301.04183"><em>&quot;Learned Disentangled Latent Representations for Scalable Image Coding for Humans and Machines&quot;</em></a> was accepted to <a href="https://www.cs.brandeis.edu/~dcc/">Data Compression Conference &#40;DCC&#41; 2023</a>.</p> <li><p>August 2022: I presented a poster titled <em>Neural Distributed Source Coding</em> at <a href="https://nasit-2022.seas.ucla.edu/poster-symposium-session-assignments/">North American School of Information Theory &#40;NASIT&#41; 2022</a>.</p> <li><p>June 2022: Interning at InterDigital – Emerging Technologies Lab in Los Altos, CA.</p> </ul> <div class=page-foot > <div class=copyright > &copy; <a href="https://github.com/ezgimez">Ezgi Özyılkan</a>. Last modified: 2024-02-14. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> + <a href="https://julialang.org">Julia</a>. </div> </div> </div>